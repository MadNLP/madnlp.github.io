@article{shinAcceleratingOptimalPower2024,
  title = {Accelerating Optimal Power Flow with {{GPUs}}: {{SIMD}} Abstraction of Nonlinear Programs and Condensed-Space Interior-Point Methods},
  shorttitle = {Accelerating Optimal Power Flow with {{GPUs}}},
  author = {Shin, Sungho and Anitescu, Mihai and Pacaud, Fran{\c c}ois},
  year = {2024},
  month = {nov},
  journal = {Electric Power Systems Research},
  volume = {236},
  pages = {110651},
  issn = {0378-7796},
  doi = {10.1016/j.epsr.2024.110651},
  urldate = {2024-10-21},
  abstract = {This paper introduces a framework for solving alternating current optimal power flow (ACOPF) problems using graphics processing units (GPUs). While GPUs have demonstrated remarkable performance in various computing domains, their application in ACOPF has been limited due to challenges associated with porting sparse automatic differentiation (AD) and sparse linear solver routines to GPUs. We address these issues with two key strategies. First, we utilize a single-instruction, multiple-data abstraction of nonlinear programs. This approach enables the specification of model equations while preserving their parallelizable structure and, in turn, facilitates the parallel AD implementation. Second, we employ a condensed-space interior-point method (IPM) with an inequality relaxation. This technique involves condensing the Karush--Kuhn--Tucker (KKT) system into a positive definite system. This strategy offers the key advantage of being able to factorize the KKT matrix without numerical pivoting, which has hampered the parallelization of the IPM algorithm. By combining these strategies, we can perform the majority of operations on GPUs while keeping the data residing in the device memory only. Comprehensive numerical benchmark results showcase the advantage of our approach. Remarkably, our implementations---MadNLP.jl and ExaModels.jl---running on NVIDIA GPUs achieve an order of magnitude speedup compared with state-of-the-art tools running on contemporary CPUs.},
  keywords = {Automatic differentiation,GPU computing,Nonlinear programming,Optimal power flow},
  file = {/Users/sushin/Zotero/storage/2TBXIKSX/Shin et al. - 2024 - Accelerating optimal power flow with GPUs SIMD abstraction of nonlinear programs and condensed-spac.pdf;/Users/sushin/Zotero/storage/KERN8HXH/S0378779624005376.html},
  eprint = {2307.16830},
  eprinttype = {arXiv},
  eprintclass = {math},
}

@article{pacaudAcceleratingCondensedInteriorPoint2023,
  title = {Accelerating {{Condensed Interior-Point Methods}} on {{SIMD}}/{{GPU Architectures}}},
  author = {Pacaud, Fran{\c c}ois and Shin, Sungho and Schanen, Michel and Maldonado, Daniel Adrian and Anitescu, Mihai},
  year = {2023},
  month = feb,
  journal = {Journal of Optimization Theory and Applications},
  issn = {1573-2878},
  doi = {10.1007/s10957-022-02129-5},
  urldate = {2023-11-21},
  abstract = {The interior-point method (IPM) has become the workhorse method for nonlinear programming. The performance of IPM is directly related to the linear solver employed to factorize the Karush--Kuhn--Tucker (KKT) system at each iteration of the algorithm. When solving large-scale nonlinear problems, state-of-the art IPM solvers rely on efficient sparse linear solvers to solve the KKT system. Instead, we propose a novel reduced-space IPM algorithm that condenses the KKT system into a dense matrix whose size is proportional to the number of degrees of freedom in the problem. Depending on where the reduction occurs, we derive two variants of the reduced-space method: linearize-then-reduce and reduce-then-linearize. We adapt their workflow so that the vast majority of computations are accelerated on GPUs. We provide extensive numerical results on the optimal power flow problem, comparing our GPU-accelerated reduced-space IPM with Knitro and a hybrid full-space IPM algorithm. By evaluating the derivatives on the GPU and solving the KKT system on the CPU, the hybrid solution is already significantly faster than the CPU-only solutions. The two reduced-space algorithms go one step further by solving the KKT system entirely on the GPU. As expected, the performance of the two reduction algorithms depends critically on the number of available degrees of freedom: They underperform the full-space method when the problem has many degrees of freedom, but the two algorithms are up to three times faster than Knitro as soon as the relative number of degrees of freedom becomes smaller.},
  langid = {english},
  file = {/Users/sushin/Zotero/storage/2FTZ699F/Pacaud et al. - 2023 - Accelerating Condensed Interior-Point Methods on S.pdf}
}
