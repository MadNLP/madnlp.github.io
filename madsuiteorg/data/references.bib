@article{pacaudAcceleratingCondensedInteriorPoint2023,
  title = {Accelerating {{Condensed Interior-Point Methods}} on {{SIMD}}/{{GPU Architectures}}},
  author = {Pacaud, Fran{\c c}ois and Shin, Sungho and Schanen, Michel and Maldonado, Daniel Adrian and Anitescu, Mihai},
  year = {2023},
  month = feb,
  journal = {Journal of Optimization Theory and Applications},
  issn = {1573-2878},
  doi = {10.1007/s10957-022-02129-5},
  urldate = {2023-11-21},
  abstract = {The interior-point method (IPM) has become the workhorse method for nonlinear programming. The performance of IPM is directly related to the linear solver employed to factorize the Karush--Kuhn--Tucker (KKT) system at each iteration of the algorithm. When solving large-scale nonlinear problems, state-of-the art IPM solvers rely on efficient sparse linear solvers to solve the KKT system. Instead, we propose a novel reduced-space IPM algorithm that condenses the KKT system into a dense matrix whose size is proportional to the number of degrees of freedom in the problem. Depending on where the reduction occurs, we derive two variants of the reduced-space method: linearize-then-reduce and reduce-then-linearize. We adapt their workflow so that the vast majority of computations are accelerated on GPUs. We provide extensive numerical results on the optimal power flow problem, comparing our GPU-accelerated reduced-space IPM with Knitro and a hybrid full-space IPM algorithm. By evaluating the derivatives on the GPU and solving the KKT system on the CPU, the hybrid solution is already significantly faster than the CPU-only solutions. The two reduced-space algorithms go one step further by solving the KKT system entirely on the GPU. As expected, the performance of the two reduction algorithms depends critically on the number of available degrees of freedom: They underperform the full-space method when the problem has many degrees of freedom, but the two algorithms are up to three times faster than Knitro as soon as the relative number of degrees of freedom becomes smaller.},
  langid = {english}
}
@misc{pacaudCondensedspaceMethodsNonlinear2024,
  title = {Condensed-Space Methods for Nonlinear Programming on {{GPUs}}},
  author = {Pacaud, Fran{\c c}ois and Shin, Sungho and Montoison, Alexis and Schanen, Michel and Anitescu, Mihai},
  year = {2024},
  month = may,
  number = {arXiv:2405.14236},
  eprint = {2405.14236},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.14236},
  urldate = {2024-05-29},
  abstract = {This paper explores two condensed-space interior-point methods to efficiently solve large-scale nonlinear programs on graphics processing units (GPUs). The interior-point method solves a sequence of symmetric indefinite linear systems, or Karush-Kuhn-Tucker (KKT) systems, which become increasingly ill-conditioned as we approach the solution. Solving a KKT system with traditional sparse factorization methods involve numerical pivoting, making parallelization difficult. A solution is to condense the KKT system into a symmetric positive-definite matrix and solve it with a Cholesky factorization, stable without pivoting. Although condensed KKT systems are more prone to ill-conditioning than the original ones, they exhibit structured ill-conditioning that mitigates the loss of accuracy. This paper compares the benefits of two recent condensed-space interior-point methods, HyKKT and LiftedKKT. We implement the two methods on GPUs using MadNLP.jl, an optimization solver interfaced with the NVIDIA sparse linear solver cuDSS and with the GPU-accelerated modeler ExaModels.jl. Our experiments on the PGLIB and the COPS benchmarks reveal that GPUs can attain up to a tenfold speed increase compared to CPUs when solving large-scale instances.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Optimization and Control}
}
@misc{pacaudGPUacceleratedNonlinearModel2024,
  title = {{{GPU-accelerated}} Nonlinear Model Predictive Control with {{ExaModels}} and {{MadNLP}}},
  author = {Pacaud, Fran{\c c}ois and Shin, Sungho},
  year = {2024},
  month = mar,
  number = {arXiv:2403.15913},
  eprint = {2403.15913},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.15913},
  urldate = {2024-05-12},
  abstract = {We investigate the potential of Graphics Processing Units (GPUs) to solve large-scale nonlinear model predictive control (NMPC) problems. We accelerate the solution of the constrained nonlinear programs in the NMPC algorithm using the GPU-accelerated automatic differentiation tool ExaModels with the interior-point solver MadNLP. The sparse linear systems formulated in the interior-point method is solved on the GPU using a hybrid solver combining an iterative method with a sparse Cholesky factorization, which harness the newly released NVIDIA cuDSS solver. Our results on the classical distillation column instance show that despite a significant pre-processing time, the hybrid solver allows to reduce the time per iteration by a factor of 25 for the largest instance.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Optimization and Control}
}

@article{pacaudParallelInteriorpointSolver2024,
  title = {Parallel Interior-Point Solver for Block-Structured Nonlinear Programs on {{SIMD}}/{{GPU}} Architectures},
  author = {Pacaud, Fran{\c c}ois and Schanen, Michel and Shin, Sungho and Maldonado, Daniel Adrian and Anitescu, Mihai},
  year = {2024},
  month = jul,
  journal = {Optimization Methods and Software},
  volume = {39},
  number = {4},
  pages = {874--897},
  publisher = {Taylor \& Francis},
  issn = {1055-6788},
  doi = {10.1080/10556788.2024.2329646},
  urldate = {2024-11-19},
  abstract = {We investigate how to port the standard interior-point method to new exascale architectures for block-structured nonlinear programs with state equations. Computationally, we decompose the interior-point algorithm into two successive operations: the evaluation of the derivatives and the solution of the associated Karush-Kuhn-Tucker (KKT) linear system. Our method accelerates both operations using two levels of parallelism. First, we distribute the computations on multiple processes using coarse parallelism. Second, each process uses SIMD/GPU accelerators locally to accelerate the operations using fine-grained parallelism. The KKT system is reduced by eliminating the inequalities and the state variables from the corresponding equations. We demonstrate our method's capability on the supercomputer Polaris, a testbed for the future exascale Aurora system. Each node is equipped with four GPUs, a setup amenable to our two-level approach. Our experiments on the stochastic optimal power flow problem show that the reduction method is 50x faster than the sparse linear solver HSL MA57 running in serial on the CPU, and 6x faster than Pardiso running in parallel on CPU on the same number of processes.},
  keywords = {distributed optimization,graphical processing units,interior-point method,multiprocessing,Nonlinear programming}
}

@article{shinAcceleratingOptimalPower2024,
  title = {Accelerating Optimal Power Flow with {{GPUs}}: {{SIMD}} Abstraction of Nonlinear Programs and Condensed-Space Interior-Point Methods},
  shorttitle = {Accelerating Optimal Power Flow with {{GPUs}}},
  author = {Shin, Sungho and Anitescu, Mihai and Pacaud, Fran{\c c}ois},
  year = {2024},
  month = nov,
  journal = {Electric Power Systems Research},
  volume = {236},
  pages = {110651},
  issn = {0378-7796},
  doi = {10.1016/j.epsr.2024.110651},
  urldate = {2024-10-21},
  abstract = {This paper introduces a framework for solving alternating current optimal power flow (ACOPF) problems using graphics processing units (GPUs). While GPUs have demonstrated remarkable performance in various computing domains, their application in ACOPF has been limited due to challenges associated with porting sparse automatic differentiation (AD) and sparse linear solver routines to GPUs. We address these issues with two key strategies. First, we utilize a single-instruction, multiple-data abstraction of nonlinear programs. This approach enables the specification of model equations while preserving their parallelizable structure and, in turn, facilitates the parallel AD implementation. Second, we employ a condensed-space interior-point method (IPM) with an inequality relaxation. This technique involves condensing the Karush--Kuhn--Tucker (KKT) system into a positive definite system. This strategy offers the key advantage of being able to factorize the KKT matrix without numerical pivoting, which has hampered the parallelization of the IPM algorithm. By combining these strategies, we can perform the majority of operations on GPUs while keeping the data residing in the device memory only. Comprehensive numerical benchmark results showcase the advantage of our approach. Remarkably, our implementations---MadNLP.jl and ExaModels.jl---running on NVIDIA GPUs achieve an order of magnitude speedup compared with state-of-the-art tools running on contemporary CPUs.},
  keywords = {Automatic differentiation,GPU computing,Nonlinear programming,Optimal power flow}
}

@inproceedings{coleExploitingGPUSIMD2023,
  title = {Exploiting {{GPU}}/{{SIMD Architectures}} for {{Solving Linear-Quadratic MPC Problems}}*},
  booktitle = {2023 {{American Control Conference}} ({{ACC}})},
  author = {Cole, David and Shin, Sungho and Pacaud, Fran{\c c}ois and Zavala, Victor M. and Anitescu, Mihai},
  year = {2023},
  month = may,
  pages = {3995--4000},
  issn = {2378-5861},
  doi = {10.23919/ACC55779.2023.10155791},
  urldate = {2024-01-19},
  abstract = {We report numerical results on solving linear-quadratic model predictive control (MPC) problems by exploiting graphics processing units (GPUs). The presented method reduces the MPC problem by eliminating the state variables and applies a condensed-space interior-point method to remove the inequality constraints in the KKT system. The final condensed matrix is positive definite and can be efficiently factorized in parallel on GPU/SIMD architectures. In addition, the size of the condensed matrix depends only on the number of controls in the problem, rendering the method particularly effective when the problem has many states but few inputs and moderate horizon length. Our numerical results for PDE-constrained problems show that the approach is an order of magnitude faster than a standard CPU implementation. We also provide an open-source Julia framework that facilitates modeling (DynamicNLPModels.jl) and solution (MadNLP.jl) of MPC problems on GPUs.}
}

@misc{shinScalableMultiPeriodAC2024,
  title = {Scalable {{Multi-Period AC Optimal Power Flow Utilizing GPUs}} with {{High Memory Capacities}}},
  author = {Shin, Sungho and Rao, Vishwas and Schanen, Michel and Maldonado, D. Adrian and Anitescu, Mihai},
  year = {2024},
  month = may,
  number = {arXiv:2405.14032},
  eprint = {2405.14032},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.14032},
  urldate = {2024-05-29},
  abstract = {This paper demonstrates the scalability of open-source GPU-accelerated nonlinear programming (NLP) frameworks -- ExaModels.jl and MadNLP.jl -- for solving multi-period alternating current (AC) optimal power flow (OPF) problems on GPUs with high memory capacities (e.g., NVIDIA GH200 with 480 GB of unified memory). There has been a growing interest in solving multi-period AC OPF problems, as the increasingly fluctuating electricity market requires operation planning over multiple periods. These problems, formerly deemed intractable, are now becoming technologically feasible to solve thanks to the advent of high-memory GPU hardware and accelerated NLP tools. This study evaluates the capability of these tools to tackle previously unsolvable multi-period AC OPF instances. Our numerical experiments, run on an NVIDIA GH200, demonstrate that we can solve a multi-period OPF instance with more than 10 million variables up to \$10{\textasciicircum}\{-4\}\$ precision in less than 10 minutes. These results demonstrate the efficacy of the GPU-accelerated NLP frameworks for the solution of extreme-scale multi-period OPF. We provide ExaModelsPower.jl, an open-source modeling tool for multi-period AC OPF models for GPUs.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Optimization and Control}
}
